Doing concurrency in python means you need to deal with GIL. You can work around it with multiprocessing, but I always afraid if that will brings more overhead. I guess if you do CPU bound tasks and have enough work load for each cores, the overhead is really doesn't matter; and if you are doing IO bound stuffs just use threading alone. But what if an IO bound task happens so frequently that the IO `query` action alone becomes a CPU bound task? For example I have sooo many TCP connections comming in at the same time that just receiving packages is computational intensive enough. If that's the case I guess you can just fork the same process and spawns threads in each processes.

Generally there is two ways of writing concurrent code. Either by lock primitive or message passing. Lock primitive are more, primitive, and I guess you see those more often in lower level C++ code (MPI is really ugly for some reason, and I still see a lot of people use openmp). Message passing decoupled threads and tasks, so at least you have some structure to work on. But under the hood message passing also need some infarstructure that relies on locks -- Queue, for instance.

Actor model and Publisher/Subscriber model are two widely used patterns for councurrency. They both kinda like variation of producer/consumer pattern, you dispatch work and some worker eventually get it somewhere in the data flow. It is just a pattern, how to use it I haven't think through yet. It might just depends on your creativity.

Did some different types of lock primitve. They are the same generally everywhere.
